# Introduction to Parallel Computing

## Course Overview

This repository contains materials and projects for the **Introduction to Parallel Computing** course. The course covers essential concepts of parallel computing, including parallel architectures and programming techniques, with a focus on shared and distributed memory systems, interconnection networks, and GPU-based massive parallel computing.

The course emphasizes the importance of understanding parallel architectures such as multiprocessor and multicomputer systems, process synchronization, and data sharing. Additionally, I developed efficient parallel programs using industry-standard **MPI** (Message Passing Interface) and gained exposure to **GPU** programming for data science and machine learning applications.

## Course Schedule

### Week 1: 
- **Topics**: Course Overview, C* Parallel Computer Simulator Installation and Usage
- **Projects**: Develop a simple sequential C* program

### Week 2: 
- **Topics**: Review of Computer Organization and Parallel Computing Support
- **Projects**: Performance analysis of sequential C* programs

### Weeks 3-4: 
- **Topics**: Parallel Process Creation, Amdahlâ€™s Law, and Optimal Speedup
- **Projects**: Parallel image smoothing and debugging with C*

### Week 5: 
- **Topics**: Multiprocessor Architecture and Process Communication
- **Projects**: Parallel Prime Number Sieve or Matrix Multiplication

### Week 6: 
- **Topics**: Data Sharing, Atomic Operations, Spinlocks
- **Projects**: Parallel Bucket Sort

### Week 7: 
- **Topics**: Synchronous Parallelism and Barrier Synchronization
- **Projects**: Parallel Jacobi Relaxation

### Week 8: 
- **Topics**: Multicomputer Architecture and Data Broadcasting
- **Projects**: Parallel Numerical Integration

### Week 9: 
- **Topics**: Message Passing, Pipeline Programming, Multicomputer Communications
- **Projects**: Numerical Integration on a Mesh

### Week 10: 
- **Topics**: Data Partitioning and Matrix Multiplication
- **Projects**: Parallel Matrix Multiplication on a Multicomputer

### Week 11: 
- **Topics**: MPI Programming and Efficient Parallel Program Mapping
- **Projects**: MPI-based Spatial Filtering on a Hypercube

### Weeks 12-13: 
- **Topics**: GPU-based Massive Parallel Computing for Cloud and Machine Learning
- **Projects**: Research and submit a technical report on GPU-based parallel systems

### Week 14: 
- **Topics**: Course Review and Final Exam
- **Deliverables**: Final Project Submission

## Key Technologies

- **MPI**: Industry-standard for distributed memory parallel programming.
- **C* Language and Simulator**: Used for developing and testing parallel programs.
- **GPU Programming**: Understanding massive parallel architectures for data-intensive tasks.

## Projects

Throughout the course, I worked on various projects, including:

- Sequential and Parallel C* Programs
- Parallel Prime Number Sieve
- Parallel Image Smoothing
- Parallel Matrix Multiplication
- MPI-based Programs for Distributed Systems
- GPU-based Research Projects
